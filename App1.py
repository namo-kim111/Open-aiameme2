import streamlit as st
import requests
import os

# Hugging Face API í‚¤ ê°€ì ¸ì˜¤ê¸°
hf_token = st.secrets["hf_token"]
headers = {"Authorization": f"Bearer {hf_token}"}

# í”„ë¡¬í”„íŠ¸ êµ¬ì„± í•¨ìˆ˜
def build_prompt(meme_name):
    return f"""
ë„ˆëŠ” ì¸í„°ë„· ë°ˆì„ ì˜ ì•„ëŠ” AIì•¼. ì‚¬ìš©ìê°€ '{meme_name}'ì´ë¼ëŠ” ë°ˆ ì´ë¦„ì„ ì…ë ¥í•˜ë©´,
1. ëœ»
2. ìœ ë˜
3. ì‚¬ìš© ì˜ˆì‹œ

ì´ ì„¸ ê°€ì§€ í•­ëª©ìœ¼ë¡œ ì§§ê³  ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ì¤˜. í•œêµ­ì–´ë¡œ.
"""

# ëª¨ë¸ API í˜¸ì¶œ í•¨ìˆ˜
def query_huggingface_model(prompt):
    api_url = "https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.1"
    response = requests.post(api_url, headers=headers, json={"inputs": prompt})
    if response.status_code == 200:
        result = response.json()
        return result[0]["generated_text"].split("ìœ ë˜")[0] + "ìœ ë˜" + result[0]["generated_text"].split("ìœ ë˜")[1]
    else:
        return f"[ì—ëŸ¬] ìƒíƒœ ì½”ë“œ: {response.status_code}, ì‘ë‹µ: {response.text}"

# Streamlit UI
st.set_page_config(page_title="AI ë°ˆ ì„¤ëª…ê¸° (HuggingFace)", page_icon="ğŸ¤–")
st.title("ğŸ¤– HuggingFace ê¸°ë°˜ AI ë°ˆ ì„¤ëª…ê¸°")
st.write("AIê°€ ë°ˆì˜ ëœ»ê³¼ ìœ ë˜ë¥¼ ì„¤ëª…í•´ë“œë¦½ë‹ˆë‹¤!")

meme_input = st.text_input("ë°ˆ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ê°“ìƒ, í‚¹ë°›ë„¤, Distracted Boyfriend)").strip()

if st.button("ì„¤ëª… ë³´ê¸°") and meme_input:
    with st.spinner("AIê°€ ì„¤ëª…ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        prompt = build_prompt(meme_input)
        explanation = query_huggingface_model(prompt)
        st.text_area("ğŸ’¬ ë°ˆ ì„¤ëª…", explanation, height=300)

st.markdown("---")
st.caption("ì œì‘: Open ì—ì´ì•„ë°ˆ + HuggingFace AI")
