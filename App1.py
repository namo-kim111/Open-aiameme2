import streamlit as st
import requests

# âœ… HuggingFace API í† í° (Streamlit Cloudì˜ Secretsì— ì…ë ¥ í•„ìš”)
hf_token = st.secrets["hf_token"]
headers = {"Authorization": f"Bearer {hf_token}"}

# âœ… ì‚¬ìš©ì ì…ë ¥ì— ê¸°ë°˜í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
def build_prompt(meme_name):
    return f"""### ì‚¬ìš©ì:
'{meme_name}'ì´ë¼ëŠ” ë°ˆì„ í•œêµ­ì–´ë¡œ ê°„ë‹¨íˆ ì„¤ëª…í•´ì¤˜.
1. ëœ»
2. ìœ ë˜
3. ì‚¬ìš© ì˜ˆì‹œ

ì´ ì„¸ ê°€ì§€ë¡œ êµ¬ì„±í•´ì¤˜.

### AI:"""

# âœ… HuggingFace API í˜¸ì¶œ í•¨ìˆ˜
def query_huggingface_model(prompt):
    api_url = "https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.1"
    payload = {"inputs": prompt, "parameters": {"max_new_tokens": 300}}
    response = requests.post(api_url, headers=headers, json=payload)
    
    if response.status_code == 200:
        try:
            result = response.json()
            return result[0].get("generated_text", "[âš ï¸ ì˜ˆìƒ ì‘ë‹µ ì—†ìŒ]")
        except Exception:
            return "[âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨]: " + str(result)
    else:
        return f"[âŒ API ì˜¤ë¥˜] ìƒíƒœ ì½”ë“œ: {response.status_code}, ì‘ë‹µ: {response.text}"

# âœ… Streamlit UI êµ¬ì„±
st.set_page_config(page_title="AI ë°ˆ ì„¤ëª…ê¸° (Mistral)", page_icon="ğŸ¤–")
st.title("ğŸ¤– Mistral ê¸°ë°˜ AI ë°ˆ ì„¤ëª…ê¸°")
st.write("AIê°€ ë°ˆì˜ ëœ»ê³¼ ìœ ë˜ë¥¼ ì„¤ëª…í•´ë“œë¦½ë‹ˆë‹¤!")

meme_input = st.text_input("ë°ˆ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ê°“ìƒ, í‚¹ë°›ë„¤, ë¦¬ë©¤ë²„ ë…¸ë¬´í˜„)").strip()

if st.button("ì„¤ëª… ë³´ê¸°") and meme_input:
    with st.spinner("AIê°€ ì„¤ëª…ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        prompt = build_prompt(meme_input)
        explanation = query_huggingface_model(prompt)
        st.text_area("ğŸ’¬ ë°ˆ ì„¤ëª…", explanation.strip(), height=300)

st.markdown("---")
st.caption("ì œì‘: Open ì—ì´ì•„ë°ˆ + Mistral AI")

st.write("ğŸ” ë°›ì€ í† í°:", hf_token[:6] + "..." if hf_token else "âŒ ì—†ìŒ")
